---
layout: post
title:  "Garantir la livraison des messages et la r√©silience sur plusieurs datacenters avec Apache Pulsar"
author: rd.team
categories: [ fr, cloud ]
image: assets/images/Architecture/resilient-messaging/mailboxes.jpg
precontent: "[üá¨üáß To English version](../ensure-cross-datacenter-guaranteed-message-delivery-and-resilience-with-apache-pulsar)<br>
_Gr√©gory Guichard, R&D Engineer at Cdiscount_<br>
_Romain Castagnet, Site Reliability Engineer at Cdiscount_<br>
_Christophe Bornet, R&D Manager at Cdiscount_"
---
Chez Cdiscount, nous traitons d'importants volumes de donn√©es en temps r√©el gr√¢ce √† des syst√®mes de messaging distribu√©s. Pour nos besoins de diffusion d'√©v√©nements, nous utilisons actuellement [Kafka](https://kafka.apache.org/ "Kafka") et pour nos besoins de queue, nous utilisons [RabbitMQ](https://www.rabbitmq.com/ "RabbitMQ"). En raison de la nature des donn√©es trait√©es par Cdiscount (commandes, paiements, etc...), il est imp√©ratif d'avoir une garantie tr√®s forte sur la livraison des messages (ne perdre aucun messages) avec la plus grande disponibilit√© possible, m√™me en cas de perte subite d'un de nos datacenters. Nous avions des difficult√©s √† garantir ce niveau d'exigence avec Kafka et RabbitMQ et cela nous a amen√© √† √©valuer [Apache Pulsar](https://pulsar.apache.org/), la toute derni√®re technologie apparue r√©cemment et qui met en avant de fortes promesses dans ce domaine.

Pr√©-requis pour les tests: ce blog utilise [docker](https://docs.docker.com/install/) et [docker-compose](https://docs.docker.com/compose/install/) pour d√©marrer simplement les noeuds des clusters dans des conteneurs isol√©s.

## Qu'est ce que Pulsar ?

Apache Pulsar est une solution de messagerie distribu√©e open-source cr√©√©e √† l'origine par Yahoo et faisant d√©sormais partie de l'Apache Software Foundation.

### Architecture

Dans l'architecture de Pulsar, nous retrouvons trois composants :

- **Broker** : composant stateless en charge de traiter les requ√™tes des clients, par le biais du protocole Pulsar ou d'un proxy websocket. Il dispose aussi d'une API REST pour les op√©rations d'administration.
- **[BookKeeper](https://bookkeeper.apache.org/)** : stockage distribu√©, scalable, performant et r√©sistant aux pannes. Pulsar utilise BookKeeper pour le stockage persistent des donn√©es. Un cluster BookKeeper est compos√© de plusieurs noeuds appel√©s bookies.
- **[Zookeeper](https://zookeeper.apache.org/)** : service assurant la coordination des brokers et de BookKeeper et dans lequel sont stock√©s √©galement les meta-donn√©es.

![](https://static1.squarespace.com/static/56894e581c1210fead06f878/t/5bb4bfb271c10b7ebdf3ca8e/1538572215597/PulsarBkZkCluster.png?format=750w)

- **Topic** : structure dans laquelle sont publi√©s et consomm√©s les messages. Dans Pulsar ou  Kafka, les topics sont persist√©s donc les messages n'ont pas besoin d'√™tre consomm√©s d√®s qu'il sont publi√©s et plusieurs consommateurs peuvent lire les m√™me messages √† des index et des vitesses diff√©rents.
- **Namespace** : permet de configurer la politique des topics qu'il va contenir (r√©tention, ACL, persistence, etc.)
- **Tenant** : Pulsar est multi-tenant, chaque tenant ayant son propre sch√©ma d'authentification et d'autorisation. Un tenant peut contenir plusieurs namespaces.

### Pourquoi nous sommes nous int√©ress√© √† Pulsar ?

Pulsar poss√®de plusieurs caract√©ristiques qui le rendent unique par rapport aux autres syst√®mes de messaging:

- **Diffusion d'√©v√©nement mais aussi Queue de messages** : en permettant √† plusieurs groupes de consommateurs d'avoir leur propre index sur la file de message, Pulsar permet les usages de diffusion d'√©v√©nement selon le m√™me principe que Kafka. Mais Pulsar permet aussi de valider le traitement des messages individuellement sans bloquer la file de message (ou sa partition) ce qui n'est pas support√© par Kafka et qui est indispensable pour les usages de queue de messages tels que possibles avec RabbitMQ.
- **R√©plication synchrone** : la r√©plication synchrone est assur√©e par BookKeeper et permet de garantir la durabilit√© des messages m√™me en cas de perte de bookies. La fonctionalit√© `rack-awareness` permet de s'assurer que les messages ne sont acquitt√©s qu'une fois qu'ils ont √©t√© √©crits sur des noeuds appartenant √† des datacenters distincts.
- **R√©plication asynchrone native** : la r√©plication asynchrone est directement int√©gr√©e √† la solution open-source et ne fait pas partie d'une offre payante. Elle permet de r√©pliquer les messages entre clusters distincts. Il faut noter que les index de lecture des consommateurs sont locaux √† un cluster et qu'il est compliqu√© de basculer un consommateur sur un cluster r√©pliqu√© en le faisant reprendre au bon index.
- **Mont√©e en charge simplifi√©e** : les brokers √©tant stateless, il est tr√®s simple d'ajouter des noeuds au cluster et m√™me de faire de l'auto-scaling. Le syst√®me de ledgers et de distribution des partitions sur plusieurs noeuds permet d'ajouter dynamiquement des bookies au cluster BookKeeper sans avoir la t√¢che d√©licate de r√©√©quilibrer les partitions.
- **Isolation des r√©gions** : il est possible de configurer le cluster pour que les consommations de messages n'impliquent les noeuds que d'une seule r√©gion en mode nominal avec une bascule sur les noeuds d'une autre r√©gion en cas de probl√®me. Plus de d√©tails ci-dessous.

## Comment mettre en place un cluster actif/passif en r√©plication synchrone avec Pulsar ?

### Pr√©sentation

Nous allons mettre en place un cluster Pulsar √©tendu sur 2 r√©gions/datacenters avec un datacenter actif et un passif qui n'est utilis√© qu'en cas de d√©faillance du datacenter actif. En mode nominal, les clients consomment sur le m√™me datacenter qu'eux, ce qui r√©duit la latence et la co√ªteuse bande passante inter-datacenter utilis√©e.

1. Pulsar est configur√© pour que les brokers choisis pour les partitions d'un topic soient sur un unique datacenter.
2. Un client publie des donn√©es sur ce topic.
3. Les donn√©es sont persist√©es de fa√ßon synchrone sur au moins un bookie du datacenter actif et au moins un bookie du datacenter passif. Ainsi en cas de perte du datacenter actif, les donn√©es seront toujours disponibles sur le second datacenter sans possibilit√© de perdre des messages.
4. Lors de la consommation, le client se connecte au broker propri√©taire du topic, ce broker va lire pr√©f√©rentiellement les donn√©es sur un bookie de la m√™me r√©gion que lui.

En cas de panne du datacenter actif, les brokers du datacenter passif deviennent automatiquement utilisables pour publier/consommer des messages. Comme il n'y a qu'un seul cluster Pulsar, la bascule est transparente pour les clients.

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/namespace_isolation.png)

Plusieurs configurations doivent √™tre mises en place afin de mettre en place un Pulsar actif/passif synchrone :

- **_Namespace Isolation Policy_** : permet d'isoler un namespace sur un ensemble de brokers. Cela permet de s'assurer assure que les brokers propri√©taires des partitions des topics sont choisis prioritairement sur une r√©gion. S'il n'y a plus assez de noeuds disponibles sur cette r√©gion (eg. en cas d'incident) alors les brokers de l'autre r√©gion peuvent √™tre choisis.
- **_Rack Awareness_** : permet que les messages soient r√©pliqu√©s de fa√ßon synchrone sur des bookies appartenant √† des racks diff√©rents.
- **_Region Awareness_** : permet que les messages soient r√©pliqu√©s de fa√ßon synchrone sur des bookies appartenant √† des r√©gions diff√©rentes.
- **_Read reordering_** : permet de privil√©gier la lecture des messages sur des bookies appartenant √† la m√™me r√©gion que le broker (lorque la fonctionnalit√© `Region Awareness` est utilis√©e)

> Note: l'exposition des fonctionnalit√©s `Region Awareness` et `Read Reordering` au projet Apache Pulsar est une contribution de Cdiscount.

### D√©monstration avec Docker

Nous allons construire une architecture comprenant 2 datacenters avec chacun 2 brokers et 2 bookies, ainsi qu'1 ZooKeeper commun.

Le premier datacenter repr√©sentera la r√©gion **_eu_** o√π l'on retrouvera 2 brokers et 2 bookies qui seront pr√©fix√©s par **_eu_**. Nous retrouverons la m√™me configuration sur le deuxi√®me datacenter qui repr√©sente la r√©gion **_us_**.

Sur chaque r√©gion nous cr√©erons un namespace en configuration active sur la r√©gion en question et passive sur l'autre.

Les commandes ci-dessous sont √† √©x√©cuter depuis la racine du dossier [docker](https://github.com/Cdiscount/IT-Blog/tree/master/samples/Architecture/resilient-messaging/docker).

#### Configuration

Nous commen√ßons par cr√©er le cluster ZooKeeper:

```
docker-compose -f docker-compose_zk.yml up -d
```

Nous cr√©ons ensuite le cluster **_mycluster_** dans ZooKeeper :

```
docker exec -it zk bin/pulsar initialize-cluster-metadata \
      --cluster mycluster \
      --zookeeper zk:2181 \
      --configuration-store zk:2181 \
      --web-service-url http://pulsar1-eu:8080 \
      --broker-service-url pulsar://pulsar1-eu:6650
```
Puis nous cr√©ons les brokers et les bookies. Les brokers sont configur√©s pour utiliser les fonctionnalit√©s `Region-aware placement policy` et `Read reordering`.
```
docker-compose -f docker-compose_sync.yml up -d
```

Il faut ensuite d√©finir les r√©gions et les racks sur lesquels vont se placer les bookies et les brokers gr√¢ce √† la commande **_set-bookie-rack_**.

```
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b bk1-eu:3181 -r eu/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b bk2-eu:3181 -r eu/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b bk1-us:3181 -r us/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b bk2-us:3181 -r us/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b pulsar1-eu:6650 -r eu/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b pulsar2-eu:6650 -r eu/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b pulsar1-us:6650 -r us/1
docker exec -it pulsar1-eu bin/pulsar-admin bookies set-bookie-rack -b pulsar2-us:6650 -r us/1
```

Nous pouvons v√©rifier la r√©gion assign√©e √† chaque bookie gr√¢ce √† la commande :

```
docker exec -it pulsar1-eu bin/pulsar-admin bookies racks-placement
```

Nous cr√©ons ensuite un tenant **_mytenant_**, et deux namespaces **_mytenant/eu_** et **_mytenant/us_** qui seront sp√©cifiques √† chaque r√©gion.

```
docker exec -it pulsar1-eu bin/pulsar-admin tenants create mytenant \
  --admin-roles admin-role \
  --allowed-clusters mycluster
docker exec -it pulsar1-eu bin/pulsar-admin namespaces create mytenant/eu
docker exec -it pulsar1-eu bin/pulsar-admin namespaces create mytenant/us
```

Nous d√©finissons ensuite une _politique d'isolation de namespace_ pour chaque r√©gion. Pour le namespace **_mytenant/eu_** du cluster **_mycluster_**, nous d√©finissons les brokers de la r√©gion **eu** comme primaires et les brokers de la r√©gion **us** comme secondaires. Les brokers de la r√©gion **us** deviendront propri√©taire du namespace si il y a moins de **un** broker disponible dans la r√©gion **eu**

```
docker exec -it pulsar1-eu bin/pulsar-admin ns-isolation-policy set mycluster ns-is-policy-eu --auto-failover-policy-params min_limit=1,usage_threshold=100 --auto-failover-policy-type min_available --namespaces "mytenant/eu" --secondary "pulsar.*" --primary "pulsar.*-eu"
```

Nous proc√©dons de la m√™me fa√ßon pour la r√©gion **_us_**

```
docker exec -it pulsar1-eu bin/pulsar-admin ns-isolation-policy set mycluster ns-is-policy-us --auto-failover-policy-params min_limit=1,usage_threshold=100 --auto-failover-policy-type min_available --namespaces "mytenant/us" --secondary "pulsar.*" --primary "pulsar.*-us"
```

Nous pouvons v√©rifier la configuration des politiques d'isolation
```
docker exec -it pulsar1-eu bin/pulsar-admin ns-isolation-policy list mycluster
```

Nous allons ensuite configurer la r√©plication synchrone des donn√©es pour chaque namespace. Nous allons choisir un **_write_quorum_** et un **_ack_quorum_** de 2 afin d'assurer la persistence des donn√©es sur chacun des datacenters gr√¢ce au placement rack-aware des bookies.

```
docker exec -it pulsar1-eu bin/pulsar-admin namespaces set-persistence --bookkeeper-ensemble 2 --bookkeeper-write-quorum 2 --bookkeeper-ack-quorum 2 -r 0 mytenant/eu
docker exec -it pulsar1-eu bin/pulsar-admin namespaces set-persistence --bookkeeper-ensemble 2 --bookkeeper-write-quorum 2 --bookkeeper-ack-quorum 2 -r 0 mytenant/us
```

Une fois tout configur√©, nous red√©marrons les brokers pour qu'ils appliquent bien toutes les configurations (notamment le changement de rack n√©cessite un reboot).
```
docker restart pulsar1-eu pulsar2-eu pulsar1-us pulsar2-us
```

#### Tests

Afin de v√©rifier le bon fonctionnement du cluster nous utilisons [Prometheus](https://prometheus.io/) qui va r√©cup√©rer les m√©triques expos√©es par les bookies. Nous utilisons √©galement [Grafana](https://grafana.com/) afin de visualiser les m√©triques sous forme de graphes.

Nous commen√ßons d'abord par cr√©er une souscription sur le topic **_mytopic_** du namespace **_eu_**

```
docker exec -it pulsar1-eu bin/pulsar-client --url pulsar://pulsar1-eu:6650 consume persistent://mytenant/eu/mytopic -s mysub -r 10 -n 0
```

Dans un autre terminal, nous produisons ensuite des messages sur le topic **_mytopic_**

```
docker exec -it pulsar1-eu bin/pulsar-perf produce persistent://mytenant/eu/mytopic -u http://pulsar1-eu:8080 -r 100
```

Sur Grafana, dans le [dashboard **_bookeeper_**](http://localhost:3000/dashboard/file/bookkeeper.json) nous pouvons regarder le graphique **Write throughput** afin de v√©rifier sur quels bookies sont persist√©s les donn√©es.

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/produceRackAware.png)

Nous voyons ici que les donn√©es sont √©crites sur les bookies **_bk1-eu_** et **_bk1-us_**, les donn√©es sont stock√©es sur un bookie de chaque r√©gion.

Nous pouvons √©galement v√©rifier ce qui se passe lors de la consommation sur le grahique **Read throughput".

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/consumeLocal.png)

Lors de la consommation les donn√©es sont lues sur le bookie de la m√™me r√©gion que le client et qui a persist√© la donn√©e, ici **_bk1_eu_**.

##### Perte d'un bookie de la r√©gion active

Nous pouvons simuler la perte d'un bookie de la r√©gion active en √©teignant le container **_bk1-eu_** :

```
docker stop bk1-eu
```

Le bookie n'√©tant plus disponible, le topic est sous-r√©pliqu√©. BookKeeper poss√®de un m√©canisme d'[auto-r√©paration](https://bookkeeper.apache.org/docs/latest/admin/autorecovery/) qui va automatiquement r√©pliquer les donn√©es du topic sur le nouveau bookie utilis√© dans la r√©gion active **_bk2-eu_** pour r√©tablir le quorum d'√©criture. C'est pourquoi apr√®s la perte de **_bk1-eu_** (√† 13h44), on observe un pic d'√©criture sur **_bk2-eu_** et un pic de lecture sur **_bk1-us_**. 
![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/perteBK1_write.png)

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/pertebk1_read.png)

Pendant le temps de l'auto-r√©paration, le client consomme les messages sur **_bk1-us_**. Une fois que **_bk2-eu_** a r√©pliqu√© les donn√©es, le client consomme les messages sur ce dernier.

##### Perte d'un datacenter complet

Nous pouvons simuler la perte d'un datacenter en √©teignant tous les containers d'un datacenter :

```
docker stop bk1-eu bk2-eu pulsar1-eu pulsar2-eu
```

Comme il n'y a plus assez de brokers pour la politique d'isolation configur√©e (min_limit=1) pour le namespace **eu**, Pulsar va basculer sur les brokers de la r√©gion **us**. Un des brokers de la r√©gion **us** est choisi comme propri√©taire du topic. Pour assurer le quorum d'√©criture de 2, les donn√©es sont persist√©es sur les 2 bookies de la r√©gion **us**.

##### Nettoyage

A la fin des tests, nous pouvons supprimer le cluster
```
docker-compose -f docker-compose_sync.yml down
docker-compose -f docker-compose_zk.yml down
```

## Comment mettre en place la geo-r√©plication asynchrone avec Pulsar ?

### Pr√©sentation

La [g√©o-r√©plication](https://pulsar.apache.org/docs/en/administration-geo/) est une r√©plication asynchrone des messages entre clusters d'une instance Pulsar. Elle permet aux consommateurs d'un cluster de recevoir les messages produits sur un autre cluster.

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/GeoReplication.png)

Sur ce diagramme, que ce soient les producers P1, P2 ou P3 qui produisent sur le topic T1 sur les clusters C1, C2 ou C3, les messages sont r√©pliqu√©s entre les diff√©rents clusters. Une fois r√©pliqu√©s, les consumers C1 et C2 peuvent traiter les messages sur leur cluster respectif.

Sans la g√©o-r√©plication, les consumers C1 et C2 ne seraient pas capable de traiter les messages produits par le producer P3.

La g√©o-r√©plication peut √™tre activ√©e entre les clusters seulement quand une configuration particuli√®re a √©t√© ajout√©e qui permet d'accorder l'acc√®s aux diff√©rents clusters :

- **_Global Namespace_** : La r√©plication utilise des topics globaux, c'est-√†-dire des topics appartenant √† un namespace global s'√©tend sur plusieurs clusters.
- **_Allowed Clusters_** : La configuration du namespace global doit permettre la r√©plication entre les diff√©rents clusters allou√©s.

### D√©monstration avec Docker

Nous allons construire une architecture comprenant 2 clusters avec chacun 2 brokers et 2 bookies, ainsi qu'un ZooKeeper commun.

Le cluster **_cluster-eu_** sera d√©di√© √† la r√©gion **_eu_** et le cluster **_cluster-us_** sera d√©di√© √† la r√©gion **_us_**.

Les commandes ci-dessous sont √† √©x√©cuter depuis la racine du dossier [docker](https://github.com/Cdiscount/IT-Blog/tree/master/samples/Architecture/resilient-messaging/docker).

#### Configuration

Nous commen√ßons par cr√©er le cluster ZooKeeper :

```
docker-compose -f docker-compose_zk.yml up -d
```

Nous cr√©ons ensuite les deux clusters Pulsar et nous les initialisons dans ZooKeeper :

```
docker exec -it zk bin/pulsar zookeeper-shell create /cluster-eu data
docker exec -it zk bin/pulsar initialize-cluster-metadata \
      --cluster cluster-eu \
      --zookeeper zk:2181/cluster-eu \
      --configuration-store zk:2181 \
      --web-service-url http://pulsar1-eu:8080 \
      --broker-service-url pulsar://pulsar1-eu:6650
docker exec -it zk bin/pulsar zookeeper-shell create /cluster-us data
docker exec -it zk bin/pulsar initialize-cluster-metadata \
      --cluster cluster-us \
      --zookeeper zk:2181/cluster-us \
      --configuration-store zk:2181 \
      --web-service-url http://pulsar1-us:8080 \
      --broker-service-url pulsar://pulsar1-us:6650
```

Nous cr√©ons les bookies et les brokers :

```
docker-compose -f docker-compose_geo.yml up -d
```

Puis nous cr√©ons un tenant **_world_**, et un namespace **_world/global_** qui sera global aux deux r√©gions.

```
docker exec -it pulsar1-eu bin/pulsar-admin tenants create world \
  --admin-roles admin-role \
  --allowed-clusters cluster-eu,cluster-us
docker exec -it pulsar1-eu bin/pulsar-admin namespaces create world/global
docker exec -it pulsar1-eu bin/pulsar-admin namespaces set-clusters world/global \
  --clusters cluster-eu,cluster-us
```

#### Tests

Nous commen√ßons d'abord par cr√©er une souscription et un consommateur sur le topic **_mytopic_** sur le **_cluster-eu_** :

```
docker exec -it zk bin/pulsar-client --url pulsar://pulsar1-eu:6650 consume persistent://world/global/mytopic -s mysub -r 100 -n 0
```

Nous pouvons ensuite produire des messages sur ce topic depuis le **_cluster-eu_** et constater que les messages sont bien re√ßus par le consommateur. Dans un autre terminal:

```
docker exec -it pulsar1-eu bin/pulsar-perf produce persistent://world/global/mytopic -u http://pulsar1-eu:8080 -r 10
```

Arr√™tons la production sur le **_cluster-eu_** et lan√ßons de la production sur le **_cluster-us_**, les messages sont aussi re√ßus par le consommateur du **_cluster-eu_** :

```
docker exec -it pulsar1-us bin/pulsar-perf produce persistent://world/global/mytopic -u http://pulsar1-us:8080 -r 10
```

Nous pouvons aussi cr√©er une souscription sur le topic **_mytopic_** sur le **_cluster-us_**

> Note: les souscriptions sur les clusters sont ind√©pendantes, il n'y a pas de "souscription globale".
> Au moment de la publication de cet article, Pulsar 2.4.0 vient de sortir avec une fonctionnalit√© de [r√©plication des souscriptions](https://pulsar.apache.org/blog/2019/07/05/Apache-Pulsar-2-4-0/#replicated-subscription). Cela permet de basculer un consommateur sur le cluster r√©pliqu√© ce qui est tr√®s pratique si perdre quelques messages (lag de r√©plication des messages) et avoir quelques doublons (lag de r√©plication des souscriptions) lors d'une bascule est acceptable. Toutefois si une consistence forte est exig√©e, la r√©plication synchrone d√©crite plus haut reste la seule solution.

Dans un troisi√®me terminal:

```
docker exec -it zk bin/pulsar-client --url pulsar://pulsar1-us:6650 consume persistent://world/global/mytopic -s mysub -r 100 -n 0
```

##### Perte d'un datacenter

Nous pouvons simuler la perte d'un datacenter en √©teignant tous les containers d'un datacenter :

```
docker stop bk1-eu bk2-eu pulsar1-eu pulsar2-eu
```

Suite √† la perte de tout le datacenter **eu**, la consommation et la production continuent de fonctionner sur le datacenter **us**. Les messages qui sont publi√©s sur **us** pendant que **eu** est √©teint seront r√©pliqu√©s quand **eu** reviendra. On peut voir que le client connect√© √† **eu** tente de se reconnecter en boucle.

Arr√™tons la production sur le **_cluster-us_**. Puis:

```
docker start bk1-eu bk2-eu pulsar1-eu pulsar2-eu
```
Lorsque le cluster **eu** est √† nouveau fonctionnel, le client se reconnecte et re√ßoit les messages qui avaient √©t√© publi√©s sur **us** pendant l'extinction.

##### Nettoyage

A la fin des tests, nous pouvons supprimer le cluster
```
docker-compose -f docker-compose_geo.yml down
docker-compose -f docker-compose_zk.yml down
```

## R√©aliser un bus de messaging actif/actif √† forte garantie de consistence des donn√©es

Comme nous l'avons vu, les namespaces Pulsar et les fonctionalit√©s de `region-awareness`  permettent de fortes garanties sur la livraison des messages tout en minimisant les √©changes inter-datacenters avec un cluster actif/passif. Mais pour nos besoins de messaging, il √©tait important d'avoir une r√©plication active/active. Pour r√©aliser cela, avons donc combin√© la r√©plication synchrone et la g√©o-r√©plication asynchrone.
Cela a plusieurs avantages:

* La r√©plication synchrone active/passive garantit qu'on ne perd aucun messages m√™me en cas de perte d'un datacenter.
* Lors d'une bascule vers les noeuds passifs, les clients ne changent pas de cluster et donc pas de souscription. Il n'y a donc pas besoin d'avoir un m√©canisme complexe pour retrouver l'index de lecture correspondant sur l'autre cluster.
* En mode nominal, les clients produisent et consomment sur leur propre r√©gion ce qui √©conomise la bande-passante consomm√©e entre les r√©gions.
* La g√©o-r√©plication permet de recevoir tous les messages quel que soit le cluster sur lequel ils ont √©t√© produits.

Il faut toutefois noter quelques inconv√©nients:

* Les brokers passifs peuvent √™tre consid√©r√©s comme une resource provisionn√©e mais inutilis√©e. Toutefois ces resources n'ont besoin d'√™tre d√©marr√©es en permanence que si l'on cherche le maximum de disponibilit√©. Si une perte momentann√©e de disponibilit√© est acceptable en cas de bascule, on peut envisager de ne d√©marrer ces brokers que quand une bascule est d√©tect√©e. On peut m√™me utiliser des resources pay√©es √† l'utilisation dans le Cloud qui ne seront utilis√©es que pendant la bascule.
* Puisqu'on ne valide un message produit que lorsqu'il a √©t√© r√©pliqu√© sur l'autre r√©gion, cela introduit une latence √† l'√©criture. Cette latence additionnelle peut-√™tre un frein pour certaines applications et il faudra alors choisir entre une consistence tr√®s forte des donn√©es et la performance d'√©criture.

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/activeActive.png)

En cas de perte de la r√©gion EU, la bascule se fait automatiquement vers la r√©gion US:

![]({{ site.baseurl }}/assets/images/Architecture/resilient-messaging/basculePulsar.png)

## Conclusion

Comme nous l'avons vu, les fonctionnalit√©s de r√©plication synchrone, d'isolation de namespace et de g√©o-r√©plication permettent de mettre en place un bus de messaging hautement r√©silient ce qui n'est pas r√©alisable actuellement avec les technologies concurrentes.
Si l'on ajoute la possibilit√© de [mutualiser les usages de diffusion d'√©v√©nements et de queueing avec une unique technologie](https://streaml.io/blog/pulsar-streaming-queuing), les [fonctionnalit√©s de traitement de flux temps r√©el](https://pulsar.apache.org/docs/fr/functions-overview/), la possibilit√© d'utiliser du [stockage √† plusieurs niveaux](https://pulsar.apache.org/docs/fr/cookbooks-tiered-storage/) pour r√©duire les co√ªts, etc... cela fait de Pulsar un candidat s√©rieux dans la course aux bus de messages.
